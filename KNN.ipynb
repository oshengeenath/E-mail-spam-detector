{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "      WORD_FREQ_MAKE  WORD_FREQ_ADDRESS  WORD_FREQ_ALL  WORD_FREQ_3D  \\\n4205            0.31                0.0           0.62           0.0   \n4206            0.00                0.0           0.00           0.0   \n4207            0.30                0.0           0.30           0.0   \n4208            0.96                0.0           0.00           0.0   \n4209            0.00                0.0           0.65           0.0   \n\n      WORD_FREQ_OUR  WORD_FREQ_OVER  WORD_FREQ_REMOVE  WORD_FREQ_INTERNET  \\\n4205           0.00            0.31               0.0                 0.0   \n4206           0.00            0.00               0.0                 0.0   \n4207           0.00            0.00               0.0                 0.0   \n4208           0.32            0.00               0.0                 0.0   \n4209           0.00            0.00               0.0                 0.0   \n\n      WORD_FREQ_ORDER  WORD_FREQ_MAIL  ...  CHAR_FREQ_;  CHAR_FREQ_(  \\\n4205              0.0             0.0  ...        0.000        0.232   \n4206              0.0             0.0  ...        0.000        0.000   \n4207              0.0             0.0  ...        0.102        0.718   \n4208              0.0             0.0  ...        0.000        0.057   \n4209              0.0             0.0  ...        0.000        0.000   \n\n      CHAR_FREQ_[  CHAR_FREQ_!  CHAR_FREQ_$  CHAR_FREQ_#  \\\n4205          0.0        0.000          0.0          0.0   \n4206          0.0        0.353          0.0          0.0   \n4207          0.0        0.000          0.0          0.0   \n4208          0.0        0.000          0.0          0.0   \n4209          0.0        0.125          0.0          0.0   \n\n      CAPITAL_RUN_LENGTH_AVERAGE  CAPITAL_RUN_LENGTH_LONGEST  \\\n4205                       1.142                           3   \n4206                       1.555                           4   \n4207                       1.404                           6   \n4208                       1.147                           5   \n4209                       1.250                           5   \n\n      CAPITAL_RUN_LENGTH_TOTAL  SPAM  \n4205                        88     0  \n4206                        14     0  \n4207                       118     0  \n4208                        78     0  \n4209                        40     0  \n\n[5 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WORD_FREQ_MAKE</th>\n      <th>WORD_FREQ_ADDRESS</th>\n      <th>WORD_FREQ_ALL</th>\n      <th>WORD_FREQ_3D</th>\n      <th>WORD_FREQ_OUR</th>\n      <th>WORD_FREQ_OVER</th>\n      <th>WORD_FREQ_REMOVE</th>\n      <th>WORD_FREQ_INTERNET</th>\n      <th>WORD_FREQ_ORDER</th>\n      <th>WORD_FREQ_MAIL</th>\n      <th>...</th>\n      <th>CHAR_FREQ_;</th>\n      <th>CHAR_FREQ_(</th>\n      <th>CHAR_FREQ_[</th>\n      <th>CHAR_FREQ_!</th>\n      <th>CHAR_FREQ_$</th>\n      <th>CHAR_FREQ_#</th>\n      <th>CAPITAL_RUN_LENGTH_AVERAGE</th>\n      <th>CAPITAL_RUN_LENGTH_LONGEST</th>\n      <th>CAPITAL_RUN_LENGTH_TOTAL</th>\n      <th>SPAM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4205</th>\n      <td>0.31</td>\n      <td>0.0</td>\n      <td>0.62</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.232</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.142</td>\n      <td>3</td>\n      <td>88</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4206</th>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.353</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.555</td>\n      <td>4</td>\n      <td>14</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4207</th>\n      <td>0.30</td>\n      <td>0.0</td>\n      <td>0.30</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.102</td>\n      <td>0.718</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.404</td>\n      <td>6</td>\n      <td>118</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4208</th>\n      <td>0.96</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.057</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.147</td>\n      <td>5</td>\n      <td>78</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4209</th>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.65</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.125</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.250</td>\n      <td>5</td>\n      <td>40</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"spamData.csv\")\n",
    "data.tail()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "(4210, 58)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "0    2531\n1    1679\nName: SPAM, dtype: int64"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"SPAM\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4210 entries, 0 to 4209\n",
      "Data columns (total 58 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   WORD_FREQ_MAKE              4210 non-null   float64\n",
      " 1   WORD_FREQ_ADDRESS           4210 non-null   float64\n",
      " 2   WORD_FREQ_ALL               4210 non-null   float64\n",
      " 3   WORD_FREQ_3D                4210 non-null   float64\n",
      " 4   WORD_FREQ_OUR               4210 non-null   float64\n",
      " 5   WORD_FREQ_OVER              4210 non-null   float64\n",
      " 6   WORD_FREQ_REMOVE            4210 non-null   float64\n",
      " 7   WORD_FREQ_INTERNET          4210 non-null   float64\n",
      " 8   WORD_FREQ_ORDER             4210 non-null   float64\n",
      " 9   WORD_FREQ_MAIL              4210 non-null   float64\n",
      " 10  WORD_FREQ_RECEIVE           4210 non-null   float64\n",
      " 11  WORD_FREQ_WILL              4210 non-null   float64\n",
      " 12  WORD_FREQ_PEOPLE            4210 non-null   float64\n",
      " 13  WORD_FREQ_REPORT            4210 non-null   float64\n",
      " 14  WORD_FREQ_ADDRESSES         4210 non-null   float64\n",
      " 15  WORD_FREQ_FREE              4210 non-null   float64\n",
      " 16  WORD_FREQ_BUSINESS          4210 non-null   float64\n",
      " 17  WORD_FREQ_EMAIL             4210 non-null   float64\n",
      " 18  WORD_FREQ_YOU               4210 non-null   float64\n",
      " 19  WORD_FREQ_CREDIT            4210 non-null   float64\n",
      " 20  WORD_FREQ_YOUR              4210 non-null   float64\n",
      " 21  WORD_FREQ_FONT              4210 non-null   float64\n",
      " 22  WORD_FREQ_000               4210 non-null   float64\n",
      " 23  WORD_FREQ_MONEY             4210 non-null   float64\n",
      " 24  WORD_FREQ_HP                4210 non-null   float64\n",
      " 25  WORD_FREQ_HPL               4210 non-null   float64\n",
      " 26  WORD_FREQ_GEORGE            4210 non-null   float64\n",
      " 27  WORD_FREQ_650               4210 non-null   float64\n",
      " 28  WORD_FREQ_LAB               4210 non-null   float64\n",
      " 29  WORD_FREQ_LABS              4210 non-null   float64\n",
      " 30  WORD_FREQ_TELNET            4210 non-null   float64\n",
      " 31  WORD_FREQ_857               4210 non-null   float64\n",
      " 32  WORD_FREQ_DATA              4210 non-null   float64\n",
      " 33  WORD_FREQ_415               4210 non-null   float64\n",
      " 34  WORD_FREQ_85                4210 non-null   float64\n",
      " 35  WORD_FREQ_TECHNOLOGY        4210 non-null   float64\n",
      " 36  WORD_FREQ_1999              4210 non-null   float64\n",
      " 37  WORD_FREQ_PARTS             4210 non-null   float64\n",
      " 38  WORD_FREQ_PM                4210 non-null   float64\n",
      " 39  WORD_FREQ_DIRECT            4210 non-null   float64\n",
      " 40  WORD_FREQ_CS                4210 non-null   float64\n",
      " 41  WORD_FREQ_MEETING           4210 non-null   float64\n",
      " 42  WORD_FREQ_ORIGINAL          4210 non-null   float64\n",
      " 43  WORD_FREQ_PROJECT           4210 non-null   float64\n",
      " 44  WORD_FREQ_RE                4210 non-null   float64\n",
      " 45  WORD_FREQ_EDU               4210 non-null   float64\n",
      " 46  WORD_FREQ_TABLE             4210 non-null   float64\n",
      " 47  WORD_FREQ_CONFERENCE        4210 non-null   float64\n",
      " 48  CHAR_FREQ_;                 4210 non-null   float64\n",
      " 49  CHAR_FREQ_(                 4210 non-null   float64\n",
      " 50  CHAR_FREQ_[                 4210 non-null   float64\n",
      " 51  CHAR_FREQ_!                 4210 non-null   float64\n",
      " 52  CHAR_FREQ_$                 4210 non-null   float64\n",
      " 53  CHAR_FREQ_#                 4210 non-null   float64\n",
      " 54  CAPITAL_RUN_LENGTH_AVERAGE  4210 non-null   float64\n",
      " 55  CAPITAL_RUN_LENGTH_LONGEST  4210 non-null   int64  \n",
      " 56  CAPITAL_RUN_LENGTH_TOTAL    4210 non-null   int64  \n",
      " 57  SPAM                        4210 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "       WORD_FREQ_MAKE  WORD_FREQ_ADDRESS  WORD_FREQ_ALL  WORD_FREQ_3D  \\\ncount     4210.000000        4210.000000    4210.000000   4210.000000   \nmean         0.104366           0.112656       0.291473      0.063078   \nstd          0.300005           0.454260       0.515719      1.352487   \nmin          0.000000           0.000000       0.000000      0.000000   \n25%          0.000000           0.000000       0.000000      0.000000   \n50%          0.000000           0.000000       0.000000      0.000000   \n75%          0.000000           0.000000       0.440000      0.000000   \nmax          4.540000          14.280000       5.100000     42.810000   \n\n       WORD_FREQ_OUR  WORD_FREQ_OVER  WORD_FREQ_REMOVE  WORD_FREQ_INTERNET  \\\ncount    4210.000000     4210.000000       4210.000000         4210.000000   \nmean        0.325321        0.096656          0.117475            0.108000   \nstd         0.687805        0.276030          0.397284            0.410282   \nmin         0.000000        0.000000          0.000000            0.000000   \n25%         0.000000        0.000000          0.000000            0.000000   \n50%         0.000000        0.000000          0.000000            0.000000   \n75%         0.410000        0.000000          0.000000            0.000000   \nmax        10.000000        5.880000          7.270000           11.110000   \n\n       WORD_FREQ_ORDER  WORD_FREQ_MAIL  ...  CHAR_FREQ_;  CHAR_FREQ_(  \\\ncount      4210.000000     4210.000000  ...  4210.000000  4210.000000   \nmean          0.091860        0.248420  ...     0.040403     0.144048   \nstd           0.282144        0.656638  ...     0.252533     0.274256   \nmin           0.000000        0.000000  ...     0.000000     0.000000   \n25%           0.000000        0.000000  ...     0.000000     0.000000   \n50%           0.000000        0.000000  ...     0.000000     0.073000   \n75%           0.000000        0.190000  ...     0.000000     0.194000   \nmax           5.260000       18.180000  ...     4.385000     9.752000   \n\n       CHAR_FREQ_[  CHAR_FREQ_!  CHAR_FREQ_$  CHAR_FREQ_#  \\\ncount  4210.000000  4210.000000  4210.000000  4210.000000   \nmean      0.017376     0.281136     0.076057     0.045798   \nstd       0.105731     0.843321     0.239708     0.435925   \nmin       0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.016000     0.000000     0.000000   \n75%       0.000000     0.331000     0.053000     0.000000   \nmax       4.081000    32.478000     6.003000    19.829000   \n\n       CAPITAL_RUN_LENGTH_AVERAGE  CAPITAL_RUN_LENGTH_LONGEST  \\\ncount                 4210.000000                 4210.000000   \nmean                     5.383896                   52.139905   \nstd                     33.147358                  199.582168   \nmin                      1.000000                    1.000000   \n25%                      1.627500                    7.000000   \n50%                      2.297000                   15.000000   \n75%                      3.706750                   44.000000   \nmax                   1102.500000                 9989.000000   \n\n       CAPITAL_RUN_LENGTH_TOTAL         SPAM  \ncount               4210.000000  4210.000000  \nmean                 291.181948     0.398812  \nstd                  618.654838     0.489712  \nmin                    1.000000     0.000000  \n25%                   40.000000     0.000000  \n50%                  101.500000     0.000000  \n75%                  273.750000     1.000000  \nmax                15841.000000     1.000000  \n\n[8 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WORD_FREQ_MAKE</th>\n      <th>WORD_FREQ_ADDRESS</th>\n      <th>WORD_FREQ_ALL</th>\n      <th>WORD_FREQ_3D</th>\n      <th>WORD_FREQ_OUR</th>\n      <th>WORD_FREQ_OVER</th>\n      <th>WORD_FREQ_REMOVE</th>\n      <th>WORD_FREQ_INTERNET</th>\n      <th>WORD_FREQ_ORDER</th>\n      <th>WORD_FREQ_MAIL</th>\n      <th>...</th>\n      <th>CHAR_FREQ_;</th>\n      <th>CHAR_FREQ_(</th>\n      <th>CHAR_FREQ_[</th>\n      <th>CHAR_FREQ_!</th>\n      <th>CHAR_FREQ_$</th>\n      <th>CHAR_FREQ_#</th>\n      <th>CAPITAL_RUN_LENGTH_AVERAGE</th>\n      <th>CAPITAL_RUN_LENGTH_LONGEST</th>\n      <th>CAPITAL_RUN_LENGTH_TOTAL</th>\n      <th>SPAM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>...</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n      <td>4210.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.104366</td>\n      <td>0.112656</td>\n      <td>0.291473</td>\n      <td>0.063078</td>\n      <td>0.325321</td>\n      <td>0.096656</td>\n      <td>0.117475</td>\n      <td>0.108000</td>\n      <td>0.091860</td>\n      <td>0.248420</td>\n      <td>...</td>\n      <td>0.040403</td>\n      <td>0.144048</td>\n      <td>0.017376</td>\n      <td>0.281136</td>\n      <td>0.076057</td>\n      <td>0.045798</td>\n      <td>5.383896</td>\n      <td>52.139905</td>\n      <td>291.181948</td>\n      <td>0.398812</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.300005</td>\n      <td>0.454260</td>\n      <td>0.515719</td>\n      <td>1.352487</td>\n      <td>0.687805</td>\n      <td>0.276030</td>\n      <td>0.397284</td>\n      <td>0.410282</td>\n      <td>0.282144</td>\n      <td>0.656638</td>\n      <td>...</td>\n      <td>0.252533</td>\n      <td>0.274256</td>\n      <td>0.105731</td>\n      <td>0.843321</td>\n      <td>0.239708</td>\n      <td>0.435925</td>\n      <td>33.147358</td>\n      <td>199.582168</td>\n      <td>618.654838</td>\n      <td>0.489712</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.627500</td>\n      <td>7.000000</td>\n      <td>40.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.073000</td>\n      <td>0.000000</td>\n      <td>0.016000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.297000</td>\n      <td>15.000000</td>\n      <td>101.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.440000</td>\n      <td>0.000000</td>\n      <td>0.410000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.190000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.194000</td>\n      <td>0.000000</td>\n      <td>0.331000</td>\n      <td>0.053000</td>\n      <td>0.000000</td>\n      <td>3.706750</td>\n      <td>44.000000</td>\n      <td>273.750000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.540000</td>\n      <td>14.280000</td>\n      <td>5.100000</td>\n      <td>42.810000</td>\n      <td>10.000000</td>\n      <td>5.880000</td>\n      <td>7.270000</td>\n      <td>11.110000</td>\n      <td>5.260000</td>\n      <td>18.180000</td>\n      <td>...</td>\n      <td>4.385000</td>\n      <td>9.752000</td>\n      <td>4.081000</td>\n      <td>32.478000</td>\n      <td>6.003000</td>\n      <td>19.829000</td>\n      <td>1102.500000</td>\n      <td>9989.000000</td>\n      <td>15841.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "   WORD_FREQ_MAKE  WORD_FREQ_ADDRESS  WORD_FREQ_ALL  WORD_FREQ_3D  \\\n0            0.00               0.64           0.64           0.0   \n1            0.21               0.28           0.50           0.0   \n2            0.06               0.00           0.71           0.0   \n3            0.00               0.00           0.00           0.0   \n4            0.00               0.00           0.00           0.0   \n\n   WORD_FREQ_OUR  WORD_FREQ_OVER  WORD_FREQ_REMOVE  WORD_FREQ_INTERNET  \\\n0           0.32            0.00              0.00                0.00   \n1           0.14            0.28              0.21                0.07   \n2           1.23            0.19              0.19                0.12   \n3           0.63            0.00              0.31                0.63   \n4           0.63            0.00              0.31                0.63   \n\n   WORD_FREQ_ORDER  WORD_FREQ_MAIL  ...  CHAR_FREQ_;  CHAR_FREQ_(  \\\n0             0.00            0.00  ...         0.00        0.000   \n1             0.00            0.94  ...         0.00        0.132   \n2             0.64            0.25  ...         0.01        0.143   \n3             0.31            0.63  ...         0.00        0.137   \n4             0.31            0.63  ...         0.00        0.135   \n\n   CHAR_FREQ_[  CHAR_FREQ_!  CHAR_FREQ_$  CHAR_FREQ_#  \\\n0          0.0        0.778        0.000        0.000   \n1          0.0        0.372        0.180        0.048   \n2          0.0        0.276        0.184        0.010   \n3          0.0        0.137        0.000        0.000   \n4          0.0        0.135        0.000        0.000   \n\n   CAPITAL_RUN_LENGTH_AVERAGE  CAPITAL_RUN_LENGTH_LONGEST  \\\n0                       3.756                          61   \n1                       5.114                         101   \n2                       9.821                         485   \n3                       3.537                          40   \n4                       3.537                          40   \n\n   CAPITAL_RUN_LENGTH_TOTAL  SPAM  \n0                       278     1  \n1                      1028     1  \n2                      2259     1  \n3                       191     1  \n4                       191     1  \n\n[5 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WORD_FREQ_MAKE</th>\n      <th>WORD_FREQ_ADDRESS</th>\n      <th>WORD_FREQ_ALL</th>\n      <th>WORD_FREQ_3D</th>\n      <th>WORD_FREQ_OUR</th>\n      <th>WORD_FREQ_OVER</th>\n      <th>WORD_FREQ_REMOVE</th>\n      <th>WORD_FREQ_INTERNET</th>\n      <th>WORD_FREQ_ORDER</th>\n      <th>WORD_FREQ_MAIL</th>\n      <th>...</th>\n      <th>CHAR_FREQ_;</th>\n      <th>CHAR_FREQ_(</th>\n      <th>CHAR_FREQ_[</th>\n      <th>CHAR_FREQ_!</th>\n      <th>CHAR_FREQ_$</th>\n      <th>CHAR_FREQ_#</th>\n      <th>CAPITAL_RUN_LENGTH_AVERAGE</th>\n      <th>CAPITAL_RUN_LENGTH_LONGEST</th>\n      <th>CAPITAL_RUN_LENGTH_TOTAL</th>\n      <th>SPAM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.778</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.756</td>\n      <td>61</td>\n      <td>278</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.01</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "   WORD_FREQ_MAKE  WORD_FREQ_ADDRESS  WORD_FREQ_ALL  WORD_FREQ_3D  \\\n0            0.00               0.64           0.64           0.0   \n1            0.21               0.28           0.50           0.0   \n2            0.06               0.00           0.71           0.0   \n3            0.00               0.00           0.00           0.0   \n4            0.00               0.00           0.00           0.0   \n\n   WORD_FREQ_OUR  WORD_FREQ_OVER  WORD_FREQ_REMOVE  WORD_FREQ_INTERNET  \\\n0           0.32            0.00              0.00                0.00   \n1           0.14            0.28              0.21                0.07   \n2           1.23            0.19              0.19                0.12   \n3           0.63            0.00              0.31                0.63   \n4           0.63            0.00              0.31                0.63   \n\n   WORD_FREQ_ORDER  WORD_FREQ_MAIL  ...  WORD_FREQ_CONFERENCE  CHAR_FREQ_;  \\\n0             0.00            0.00  ...                   0.0         0.00   \n1             0.00            0.94  ...                   0.0         0.00   \n2             0.64            0.25  ...                   0.0         0.01   \n3             0.31            0.63  ...                   0.0         0.00   \n4             0.31            0.63  ...                   0.0         0.00   \n\n   CHAR_FREQ_(  CHAR_FREQ_[  CHAR_FREQ_!  CHAR_FREQ_$  CHAR_FREQ_#  \\\n0        0.000          0.0        0.778        0.000        0.000   \n1        0.132          0.0        0.372        0.180        0.048   \n2        0.143          0.0        0.276        0.184        0.010   \n3        0.137          0.0        0.137        0.000        0.000   \n4        0.135          0.0        0.135        0.000        0.000   \n\n   CAPITAL_RUN_LENGTH_AVERAGE  CAPITAL_RUN_LENGTH_LONGEST  \\\n0                       3.756                          61   \n1                       5.114                         101   \n2                       9.821                         485   \n3                       3.537                          40   \n4                       3.537                          40   \n\n   CAPITAL_RUN_LENGTH_TOTAL  \n0                       278  \n1                      1028  \n2                      2259  \n3                       191  \n4                       191  \n\n[5 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WORD_FREQ_MAKE</th>\n      <th>WORD_FREQ_ADDRESS</th>\n      <th>WORD_FREQ_ALL</th>\n      <th>WORD_FREQ_3D</th>\n      <th>WORD_FREQ_OUR</th>\n      <th>WORD_FREQ_OVER</th>\n      <th>WORD_FREQ_REMOVE</th>\n      <th>WORD_FREQ_INTERNET</th>\n      <th>WORD_FREQ_ORDER</th>\n      <th>WORD_FREQ_MAIL</th>\n      <th>...</th>\n      <th>WORD_FREQ_CONFERENCE</th>\n      <th>CHAR_FREQ_;</th>\n      <th>CHAR_FREQ_(</th>\n      <th>CHAR_FREQ_[</th>\n      <th>CHAR_FREQ_!</th>\n      <th>CHAR_FREQ_$</th>\n      <th>CHAR_FREQ_#</th>\n      <th>CAPITAL_RUN_LENGTH_AVERAGE</th>\n      <th>CAPITAL_RUN_LENGTH_LONGEST</th>\n      <th>CAPITAL_RUN_LENGTH_TOTAL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.778</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.756</td>\n      <td>61</td>\n      <td>278</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.iloc[:,0:57]\n",
    "x.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "0    1\n1    1\n2    1\n3    1\n4    1\nName: SPAM, dtype: int64"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.iloc[:,-1]\n",
    "y.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-3.47921635e-01,  1.16102457e+00,  6.75889440e-01,\n        -4.66443573e-02, -7.73663409e-03, -3.50204578e-01,\n        -2.95730784e-01, -2.63264582e-01, -3.25616842e-01,\n        -3.78366394e-01, -3.07836454e-01,  8.47631759e-02,\n        -3.15758922e-01, -1.76898989e-01, -1.85015552e-01,\n         8.29793377e-02, -3.25938821e-01,  2.03531251e+00,\n         1.19664046e-01, -1.68067611e-01,  1.30488674e-01,\n        -1.22848361e-01, -2.86432856e-01, -2.10737045e-01,\n        -3.42409883e-01, -3.08500411e-01, -2.08345688e-01,\n        -2.40162580e-01, -1.70587241e-01, -2.36121186e-01,\n        -1.64102355e-01, -1.49368151e-01, -1.79821620e-01,\n        -1.51690933e-01, -2.03472786e-01, -2.57147796e-01,\n        -3.38036502e-01, -6.15660353e-02, -1.87653204e-01,\n        -1.91804019e-01, -1.30233192e-01, -1.78329248e-01,\n        -2.10365679e-01, -1.31986835e-01, -3.06106831e-01,\n        -2.04024791e-01, -7.30943204e-02, -1.16407085e-01,\n        -1.60010417e-01, -5.25294172e-01, -1.64364088e-01,\n         5.89245610e-01, -3.17325340e-01, -1.05071082e-01,\n        -4.91167073e-02,  4.43984929e-02, -2.13099660e-02],\n       [ 3.52150097e-01,  3.68432802e-01,  4.04391290e-01,\n        -4.66443573e-02, -2.69469728e-01,  6.64297428e-01,\n         2.32921552e-01, -9.26301309e-02, -3.25616842e-01,\n         1.05333717e+00,  8.32570874e-01,  2.54752523e-01,\n         1.78594684e+00,  4.29994283e-01,  3.93121265e-01,\n        -1.42743048e-01, -1.72971706e-01,  1.68637721e-01,\n         9.90433966e-01, -1.68067611e-01,  6.78688678e-01,\n        -1.22848361e-01,  9.37610859e-01,  7.85391401e-01,\n        -3.42409883e-01, -3.08500411e-01, -2.08345688e-01,\n        -2.40162580e-01, -1.70587241e-01, -2.36121186e-01,\n        -1.64102355e-01, -1.49368151e-01, -1.79821620e-01,\n        -1.51690933e-01, -2.03472786e-01, -2.57147796e-01,\n        -1.73120174e-01, -6.15660353e-02, -1.87653204e-01,\n        -1.91804019e-01, -1.30233192e-01, -1.78329248e-01,\n        -2.10365679e-01, -1.31986835e-01, -3.06106831e-01,\n        -2.04024791e-01, -7.30943204e-02, -1.16407085e-01,\n        -1.60010417e-01, -4.39356976e-02, -1.64364088e-01,\n         1.07758645e-01,  4.33676049e-01,  5.05279381e-03,\n        -8.14326685e-03,  2.44841007e-01,  1.19114170e+00],\n       [-1.47901140e-01, -2.48027464e-01,  8.11638515e-01,\n        -4.66443573e-02,  1.31546956e+00,  3.38207498e-01,\n         1.82573711e-01,  2.92516203e-02,  1.94299955e+00,\n         2.40582925e-03,  1.75575776e+00, -1.30556664e-01,\n         7.22482957e-02, -1.76898989e-01,  7.04169466e+00,\n        -2.43064108e-01, -1.94824151e-01,  1.55478237e+00,\n        -2.02633911e-01,  4.64940540e-01, -2.61082758e-01,\n        -1.22848361e-01,  3.01563856e+00, -7.17423779e-02,\n        -3.42409883e-01, -3.08500411e-01, -2.08345688e-01,\n        -2.40162580e-01, -1.70587241e-01, -2.36121186e-01,\n        -1.64102355e-01, -1.49368151e-01, -1.79821620e-01,\n        -1.51690933e-01, -2.03472786e-01, -2.57147796e-01,\n        -3.38036502e-01, -6.15660353e-02, -1.87653204e-01,\n        -3.99994426e-03, -1.30233192e-01, -1.78329248e-01,\n         3.07224255e-01, -1.31986835e-01, -2.48733945e-01,\n        -1.39383375e-01, -7.30943204e-02, -1.16407085e-01,\n        -1.20406905e-01, -3.82249145e-03, -1.64364088e-01,\n        -6.09048925e-03,  4.50364968e-01, -8.21286077e-02,\n         1.33875867e-01,  2.16908914e+00,  3.18117903e+00],\n       [-3.47921635e-01, -2.48027464e-01, -5.65244961e-01,\n        -4.66443573e-02,  4.43025917e-01, -3.50204578e-01,\n         4.84660760e-01,  1.27244548e+00,  7.73244225e-01,\n         5.81179609e-01,  1.37562198e+00, -2.89213388e-01,\n         6.86593057e-01, -1.76898989e-01, -1.85015552e-01,\n         7.04392052e-02, -3.25938821e-01, -3.48856280e-01,\n         8.26457812e-01, -1.68067611e-01, -4.35114506e-01,\n        -1.22848361e-01, -2.86432856e-01, -2.10737045e-01,\n        -3.42409883e-01, -3.08500411e-01, -2.08345688e-01,\n        -2.40162580e-01, -1.70587241e-01, -2.36121186e-01,\n        -1.64102355e-01, -1.49368151e-01, -1.79821620e-01,\n        -1.51690933e-01, -2.03472786e-01, -2.57147796e-01,\n        -3.38036502e-01, -6.15660353e-02, -1.87653204e-01,\n        -1.91804019e-01, -1.30233192e-01, -1.78329248e-01,\n        -2.10365679e-01, -1.31986835e-01, -3.06106831e-01,\n        -2.04024791e-01, -7.30943204e-02, -1.16407085e-01,\n        -1.60010417e-01, -2.57024221e-02, -1.64364088e-01,\n        -1.70934549e-01, -3.17325340e-01, -1.05071082e-01,\n        -5.57243534e-02, -6.08338268e-02, -1.61954359e-01],\n       [-3.47921635e-01, -2.48027464e-01, -5.65244961e-01,\n        -4.66443573e-02,  4.43025917e-01, -3.50204578e-01,\n         4.84660760e-01,  1.27244548e+00,  7.73244225e-01,\n         5.81179609e-01,  1.37562198e+00, -2.89213388e-01,\n         6.86593057e-01, -1.76898989e-01, -1.85015552e-01,\n         7.04392052e-02, -3.25938821e-01, -3.48856280e-01,\n         8.26457812e-01, -1.68067611e-01, -4.35114506e-01,\n        -1.22848361e-01, -2.86432856e-01, -2.10737045e-01,\n        -3.42409883e-01, -3.08500411e-01, -2.08345688e-01,\n        -2.40162580e-01, -1.70587241e-01, -2.36121186e-01,\n        -1.64102355e-01, -1.49368151e-01, -1.79821620e-01,\n        -1.51690933e-01, -2.03472786e-01, -2.57147796e-01,\n        -3.38036502e-01, -6.15660353e-02, -1.87653204e-01,\n        -1.91804019e-01, -1.30233192e-01, -1.78329248e-01,\n        -2.10365679e-01, -1.31986835e-01, -3.06106831e-01,\n        -2.04024791e-01, -7.30943204e-02, -1.16407085e-01,\n        -1.60010417e-01, -3.29957323e-02, -1.64364088e-01,\n        -1.73306405e-01, -3.17325340e-01, -1.05071082e-01,\n        -5.57243534e-02, -6.08338268e-02, -1.61954359e-01]])"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = scaler.fit_transform(x)\n",
    "x[0:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "(3368, 57)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "(842, 57)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier(n_neighbors=1)",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(x_train,y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 0, 0, 0], dtype=int64)"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred[0:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "1444    1\n2998    0\n4157    0\n3442    0\n3202    0\nName: SPAM, dtype: int64"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9168646080760094"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test,pred)\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[469,  35],\n       [ 35, 303]], dtype=int64)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,pred)\n",
    "cm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "     y_test  pred\n0         1     1\n1         0     0\n2         0     0\n3         0     0\n4         0     0\n..      ...   ...\n837       1     1\n838       0     0\n839       1     1\n840       1     1\n841       0     0\n\n[842 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y_test</th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>837</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>838</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>839</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>840</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>841</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>842 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data=[y_test.values],index=[\"y_test\",\"pred\"])\n",
    "results.transpose()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "correct_sum = []\n",
    "for i in range(1,30):\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(x_train,y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    correct = np.sum(pred==y_test)\n",
    "    correct_sum.append(correct)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "[772,\n 756,\n 775,\n 760,\n 770,\n 763,\n 763,\n 760,\n 766,\n 761,\n 771,\n 761,\n 766,\n 762,\n 765,\n 756,\n 758,\n 755,\n 757,\n 750,\n 752,\n 748,\n 751,\n 746,\n 746,\n 742,\n 747,\n 741,\n 741]"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "    1    2    3    4    5    6    7    8    9    10  ...   20   21   22   23  \\\n0  772  756  775  760  770  763  763  760  766  761  ...  750  752  748  751   \n\n    24   25   26   27   28   29  \n0  746  746  742  747  741  741  \n\n[1 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>772</td>\n      <td>756</td>\n      <td>775</td>\n      <td>760</td>\n      <td>770</td>\n      <td>763</td>\n      <td>763</td>\n      <td>760</td>\n      <td>766</td>\n      <td>761</td>\n      <td>...</td>\n      <td>750</td>\n      <td>752</td>\n      <td>748</td>\n      <td>751</td>\n      <td>746</td>\n      <td>746</td>\n      <td>742</td>\n      <td>747</td>\n      <td>741</td>\n      <td>741</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data=correct_sum)\n",
    "results.index = results.index+1\n",
    "results.T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9204275534441805"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
